{"cells":[{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":167,"status":"ok","timestamp":1680660969043,"user":{"displayName":"杨宇鹏","userId":"06536559689418416898"},"user_tz":240},"id":"ZTdfA7eqnR84","outputId":"36bafcbd-65bb-441f-b94a-05d86c45e62a"},"outputs":[{"name":"stdout","output_type":"stream","text":["cpu\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import KFold\n","from sklearn.decomposition import PCA\n","from sklearn.metrics import balanced_accuracy_score\n","from sklearn.metrics import roc_auc_score\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader\n","from torch.utils.data import TensorDataset\n","\n","if torch.cuda.is_available(): DEVICE = torch.device('cuda')\n","else: DEVICE = torch.device('cpu')\n","OUTPUT_DIM = 2\n","print(DEVICE)"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":17795,"status":"ok","timestamp":1680660988154,"user":{"displayName":"杨宇鹏","userId":"06536559689418416898"},"user_tz":240},"id":"oa5HlBTdnR88"},"outputs":[],"source":["try:\n","    all_x = pd.read_csv(\"x_train.csv\", dtype={\"ID\": \"int\"})\n","    X_test = pd.read_csv(\"x_test.csv\", dtype={\"ID\": \"int\"})\n","except:\n","    print(\"Please first run 1_preprocess.ipynb!\")\n","all_x.rename(columns={\"Unnamed: 0\": \"Hour\"}, inplace=True)\n","X_test.rename(columns={\"Unnamed: 0\": \"Hour\"}, inplace=True)\n","all_y = pd.read_csv(\"train_outcome.csv\")\n","result_df = pd.read_csv(\"test_nolabel.csv\")\n","pred_proba_df = pd.DataFrame()\n","\n","# Remember the sequence length (number of rows) for each patient.\n","# It can help transform the 2D dataframe into 3D tensor later.\n","max_hour = np.array((), dtype=\"int16\")\n","for cur_id in all_y[\"ID\"]:\n","    max_hour = np.append(arr=max_hour, values=np.max(all_x[all_x[\"ID\"] == cur_id][\"Hour\"]))\n","max_hour_test = np.array((), dtype=\"int16\")\n","for cur_id in result_df[\"ID\"]:\n","    max_hour_test = np.append(arr=max_hour_test, values=np.max(X_test[X_test[\"ID\"] == cur_id][\"Hour\"]))"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1680660988155,"user":{"displayName":"杨宇鹏","userId":"06536559689418416898"},"user_tz":240},"id":"k5sjMKngnR8-"},"outputs":[],"source":["# Do padding and packing for time series.\n","# If the patients has more records than needed, simply drop the older records.\n","# If the patients has less records than needed, fill in 0 so that the neural\n","# networks will not calculate the gradients for the 0 part.\n","def pad_pack(df: pd.DataFrame, max_hour: np.ndarray, seq_len: float) -> pd.DataFrame:\n","    result = pd.DataFrame(np.zeros((len(max_hour) * seq_len, df.shape[1])))\n","    pointer = 0\n","    i = 0\n","    for hour in max_hour:\n","        if hour < seq_len:\n","            # padding\n","            result.iloc[(i*seq_len):(i*seq_len+hour),:] = df.iloc[pointer:(pointer+hour),:]\n","        else:\n","            # packing\n","            result.iloc[(i*seq_len):(i*seq_len+seq_len),:] = df.iloc[(pointer+hour-seq_len):(pointer+hour),:]\n","        pointer += hour\n","        i += 1\n","    return result"]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1680660988156,"user":{"displayName":"杨宇鹏","userId":"06536559689418416898"},"user_tz":240},"id":"wmkxeB8cnR9B"},"outputs":[],"source":["# The core of the LSTM model.\n","# The fully connected layer will give out the numerical value of the two classes.\n","class LSTMModel(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, output_size, drop_out):\n","        super().__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=drop_out)\n","        self.fc = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, x):\n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n","        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n","        x = x.float()\n","        h0 = h0.float()\n","        c0 = c0.float()\n","        out, _ = self.lstm(x, (h0.detach(), c0.detach()))\n","        out = self.fc(out[:, -1, :])\n","        return out"]},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1680660988157,"user":{"displayName":"杨宇鹏","userId":"06536559689418416898"},"user_tz":240},"id":"uBH9Ey7cnR9B"},"outputs":[],"source":["def training(model, train_loader, criterion, optimizer, device):\n","    model.train()\n","    running_loss = 0.0\n","\n","    for i, (inputs, labels) in enumerate(train_loader):\n","        # Use GPU if available\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        # clear the gradient\n","        optimizer.zero_grad()\n","        # Do training in batches\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        \n","        running_loss += loss.item() * inputs.size(0)\n","\n","    epoch_loss = running_loss / len(train_loader.dataset)\n","    return epoch_loss"]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1680660988157,"user":{"displayName":"杨宇鹏","userId":"06536559689418416898"},"user_tz":240},"id":"AdfGF2HYnR9D"},"outputs":[],"source":["def evaluate(model, data_loader, criterion, device):\n","    model.eval()\n","    running_loss = 0.0\n","    pred_label_arr = np.array(())\n","    pred_proba_arr = np.array(())\n","    true_label_arr = np.array(())\n","\n","    with torch.no_grad():\n","        for i, (inputs, labels) in enumerate(data_loader):\n","            # Use GPU if available\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","\n","            running_loss += loss.item() * inputs.size(0)\n","            # Derive the prediction label\n","            _, pred_label = torch.max(outputs.data, 1)\n","            # Derive the prediction probability\n","            pred_proba = torch.softmax(outputs.data, 1)[:, 1]\n","\n","            pred_label_arr = np.append(pred_label_arr, pred_label.detach().cpu().numpy())\n","            pred_proba_arr = np.append(pred_proba_arr, pred_proba.detach().cpu().numpy())\n","            true_label_arr = np.append(true_label_arr, labels.detach().cpu().numpy())\n","        \n","        # Calculate the validation loss, BAR, and AUC\n","        epoch_loss = running_loss / len(data_loader.dataset)\n","        epoch_bqr = balanced_accuracy_score(true_label_arr, pred_label_arr)\n","        epoch_auc = roc_auc_score(true_label_arr, pred_proba_arr)\n","\n","    return epoch_loss, epoch_bqr, epoch_auc"]},{"cell_type":"code","execution_count":41,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1680660988158,"user":{"displayName":"杨宇鹏","userId":"06536559689418416898"},"user_tz":240},"id":"Zml2SLi0nR9E"},"outputs":[],"source":["def predict(model, data_loader, criterion, device):\n","    model.eval()\n","    pred_proba_arr = np.array(())\n","\n","    with torch.no_grad():\n","        for i, (inputs, _) in enumerate(data_loader):\n","            # Use GPU if available\n","            inputs = inputs.to(device)\n","\n","            outputs = model(inputs)\n","\n","            # Derive the prediction probability\n","            pred_proba = torch.softmax(outputs.data, 1)[:, 1]\n","\n","            pred_proba_arr = np.append(pred_proba_arr, pred_proba.detach().cpu().numpy())\n","\n","    return pred_proba_arr"]},{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1680660988158,"user":{"displayName":"杨宇鹏","userId":"06536559689418416898"},"user_tz":240},"id":"i6lTtbg3nR9F"},"outputs":[],"source":["def cross_validation(\n","        all_x,\n","        all_y,\n","        all_test,\n","        max_hour,\n","        max_hour_test,\n","        num_folds,\n","        num_epochs,\n","        hidden_dim,\n","        layer_dim,\n","        batch_size,\n","        learning_rate,\n","        device,\n","        dropout,\n","        seq_len,\n","        random_seed\n","    ):\n","    # Model initialization\n","    kfold = KFold(n_splits=num_folds, shuffle=True, random_state=random_seed)\n","    imputer = SimpleImputer()\n","    scaler = StandardScaler()\n","    pca = PCA(random_state=random_seed)\n","    early_stopping_rounds = 5\n","    criterion = nn.CrossEntropyLoss()\n","    bar_list = []\n","    auc_list = []\n","    pred_df = pd.DataFrame()\n","    np.random.seed(seed=random_seed)\n","    torch.manual_seed(seed=random_seed)\n","\n","    for fold, (train_index, valid_index) in enumerate(kfold.split(all_y)):\n","        bar = 0\n","        auc = 0\n","        print(f'Fold: {fold + 1}')\n","        \n","        train_id = all_y.loc[train_index, \"ID\"]\n","        valid_id = all_y.loc[valid_index, \"ID\"]\n","        X_train = all_x[all_x[\"ID\"].isin(train_id)]\n","        X_valid = all_x[all_x[\"ID\"].isin(valid_id)]\n","        y_train = all_y[all_y[\"ID\"].isin(train_id)][\"Outcome\"]\n","        y_valid = all_y[all_y[\"ID\"].isin(valid_id)][\"Outcome\"]\n","        X_test = all_test\n","\n","        # drop ID\n","        X_train = X_train.drop([\"ID\"], axis=1)\n","        X_valid = X_valid.drop([\"ID\"], axis=1)\n","        X_test = X_test.drop([\"ID\"], axis=1)\n","        \n","        # impute\n","        imputer.fit(X_train)\n","        X_train = imputer.transform(X_train)\n","        X_valid = imputer.transform(X_valid)\n","        X_test = imputer.transform(X_test)\n","\n","        # scale\n","        scaler.fit(X_train)\n","        X_train = scaler.transform(X_train)\n","        X_valid = scaler.transform(X_valid)\n","        X_test = scaler.transform(X_test)\n","\n","        # pca\n","        pca.fit(X_train)\n","        X_train = pca.transform(X_train)\n","        X_valid = pca.transform(X_valid)\n","        X_test = pca.transform(X_test)\n","\n","        # padding and packing\n","        X_train = pd.DataFrame(X_train)\n","        X_valid = pd.DataFrame(X_valid)\n","        X_test = pd.DataFrame(X_test)\n","        train_max_hour = max_hour[train_index]\n","        valid_max_hour = max_hour[valid_index]\n","        X_train = pad_pack(X_train, train_max_hour, seq_len)\n","        X_valid = pad_pack(X_valid, valid_max_hour, seq_len)\n","        X_test = pad_pack(X_test, max_hour_test, seq_len)\n","\n","        idx0 = np.where(y_train == 0)[0]\n","        idx1 = np.where(y_train == 1)[0]\n","\n","        # model construction\n","        input_dim = X_train.shape[1]\n","        model = LSTMModel(input_dim, hidden_dim, layer_dim, OUTPUT_DIM, dropout).to(device)\n","        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","        \n","        # Convert 2D array into 3D tensor with the help of max_hour\n","        X_train = X_train.to_numpy()\n","        X_valid = X_valid.to_numpy()\n","        X_test = X_test.to_numpy()\n","        X_train = X_train.reshape((int(X_train.shape[0] / seq_len), seq_len, X_train.shape[1]))\n","        X_valid = X_valid.reshape((int(X_valid.shape[0] / seq_len), seq_len, X_valid.shape[1]))\n","        X_test = X_test.reshape((int(X_test.shape[0] / seq_len), seq_len, X_test.shape[1]))\n","        X_train = torch.from_numpy(X_train).to(device)\n","        y_train = torch.from_numpy(np.array(y_train)).to(device)\n","        X_valid = torch.from_numpy(X_valid).to(device)\n","        y_valid = torch.from_numpy(np.array(y_valid)).to(device)\n","        X_test = torch.from_numpy(X_test).to(device)\n","        temp_labels = torch.from_numpy(np.zeros_like(X_test.cpu())).to(device)\n","        \n","        # resample class 1 so that class 1 will have the same length with class 0\n","        if len(idx0) > (3 * len(idx1)):\n","            idx1 = np.random.choice(idx1, size=len(idx0))\n","            y_train = torch.cat((y_train[idx0], y_train[idx1]), dim=0)\n","            X_train = torch.cat((X_train[idx0], X_train[idx1]), dim=0)\n","            print(\"resample invoked\")\n","        \n","        train = TensorDataset(X_train, y_train)\n","        valid = TensorDataset(X_valid, y_valid)\n","        test = TensorDataset(X_test, temp_labels)\n","        train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n","        valid_loader = DataLoader(valid, batch_size=batch_size, shuffle=True)\n","        test_loader = DataLoader(test, batch_size=batch_size, shuffle=False)\n","\n","        best_model = None\n","        best_val_loss = 1e10\n","        patience = 0\n","        for epoch in range(num_epochs):\n","            # Training\n","            train_loss = training(model, train_loader, criterion, optimizer, device)\n","            # Validating\n","            val_loss, val_bar, val_auc = evaluate(model, valid_loader, criterion, device)\n","\n","            print(f'Epoch: {epoch+1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val BAR: {val_bar:.4f}, Val AUC:{val_auc:.4f}')\n","            \n","            # Stop early if validation loss do not decrease in 5 epochs\n","            if val_loss < best_val_loss:\n","                best_val_loss = val_loss\n","                best_model = model\n","                patience = 0\n","                bar = val_bar\n","                auc = val_auc\n","            else:\n","                patience += 1\n","\n","            if patience == early_stopping_rounds:\n","                print('Early stopping triggered')\n","                break\n","        y_pred = predict(best_model, test_loader, criterion, device)\n","        pred_df[str(fold)] = y_pred\n","        bar_list.append(bar)\n","        auc_list.append(auc)\n","    # pred_df.to_csv(\"pred_prob5.csv\")\n","    return bar_list, auc_list, pred_df"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dGsq5PNPnR9G","outputId":"ad8aa950-afae-4ce5-ecf9-4247cad689b0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold: 1\n","resample invoked\n","Epoch: 1, Train Loss: 0.5086, Val Loss: 0.3738, Val BAR: 0.8179, Val AUC:0.8773\n","Epoch: 2, Train Loss: 0.3409, Val Loss: 0.3309, Val BAR: 0.8197, Val AUC:0.9025\n","Epoch: 3, Train Loss: 0.2912, Val Loss: 0.3468, Val BAR: 0.8235, Val AUC:0.9053\n","Epoch: 4, Train Loss: 0.2558, Val Loss: 0.3451, Val BAR: 0.8116, Val AUC:0.8960\n","Epoch: 5, Train Loss: 0.2283, Val Loss: 0.3220, Val BAR: 0.8168, Val AUC:0.8996\n","Epoch: 6, Train Loss: 0.2028, Val Loss: 0.3072, Val BAR: 0.8154, Val AUC:0.8938\n","Epoch: 7, Train Loss: 0.1785, Val Loss: 0.3669, Val BAR: 0.8117, Val AUC:0.8789\n","Epoch: 8, Train Loss: 0.1587, Val Loss: 0.3984, Val BAR: 0.8036, Val AUC:0.8744\n","Epoch: 9, Train Loss: 0.1406, Val Loss: 0.3722, Val BAR: 0.8089, Val AUC:0.8753\n","Epoch: 10, Train Loss: 0.1217, Val Loss: 0.4363, Val BAR: 0.8072, Val AUC:0.8656\n","Epoch: 11, Train Loss: 0.1059, Val Loss: 0.4501, Val BAR: 0.8036, Val AUC:0.8620\n","Early stopping triggered\n","Fold: 2\n","resample invoked\n","Epoch: 1, Train Loss: 0.5123, Val Loss: 0.3483, Val BAR: 0.8111, Val AUC:0.9051\n","Epoch: 2, Train Loss: 0.3409, Val Loss: 0.3457, Val BAR: 0.8221, Val AUC:0.9111\n","Epoch: 3, Train Loss: 0.2882, Val Loss: 0.3212, Val BAR: 0.8268, Val AUC:0.9082\n","Epoch: 4, Train Loss: 0.2556, Val Loss: 0.3164, Val BAR: 0.8311, Val AUC:0.9034\n","Epoch: 5, Train Loss: 0.2278, Val Loss: 0.3078, Val BAR: 0.8103, Val AUC:0.8974\n","Epoch: 6, Train Loss: 0.2036, Val Loss: 0.3359, Val BAR: 0.8125, Val AUC:0.8935\n","Epoch: 7, Train Loss: 0.1802, Val Loss: 0.3451, Val BAR: 0.8171, Val AUC:0.8890\n","Epoch: 8, Train Loss: 0.1593, Val Loss: 0.3659, Val BAR: 0.8000, Val AUC:0.8810\n","Epoch: 9, Train Loss: 0.1400, Val Loss: 0.4082, Val BAR: 0.7999, Val AUC:0.8759\n","Epoch: 10, Train Loss: 0.1219, Val Loss: 0.4051, Val BAR: 0.7962, Val AUC:0.8718\n","Early stopping triggered\n","Fold: 3\n","resample invoked\n","Epoch: 1, Train Loss: 0.5112, Val Loss: 0.4011, Val BAR: 0.8220, Val AUC:0.8947\n","Epoch: 2, Train Loss: 0.3528, Val Loss: 0.3243, Val BAR: 0.8132, Val AUC:0.9033\n","Epoch: 3, Train Loss: 0.3028, Val Loss: 0.3447, Val BAR: 0.8212, Val AUC:0.8973\n","Epoch: 4, Train Loss: 0.2671, Val Loss: 0.3447, Val BAR: 0.8270, Val AUC:0.9008\n","Epoch: 5, Train Loss: 0.2382, Val Loss: 0.3321, Val BAR: 0.8140, Val AUC:0.8932\n","Epoch: 6, Train Loss: 0.2092, Val Loss: 0.3990, Val BAR: 0.8089, Val AUC:0.8878\n","Epoch: 7, Train Loss: 0.1861, Val Loss: 0.3703, Val BAR: 0.8090, Val AUC:0.8817\n","Early stopping triggered\n","Fold: 4\n","resample invoked\n","Epoch: 1, Train Loss: 0.5098, Val Loss: 0.3625, Val BAR: 0.8376, Val AUC:0.9112\n","Epoch: 2, Train Loss: 0.3444, Val Loss: 0.2896, Val BAR: 0.8461, Val AUC:0.9163\n","Epoch: 3, Train Loss: 0.2936, Val Loss: 0.3193, Val BAR: 0.8530, Val AUC:0.9160\n","Epoch: 4, Train Loss: 0.2604, Val Loss: 0.3007, Val BAR: 0.8411, Val AUC:0.9121\n","Epoch: 5, Train Loss: 0.2346, Val Loss: 0.2930, Val BAR: 0.8484, Val AUC:0.9168\n","Epoch: 6, Train Loss: 0.2060, Val Loss: 0.3031, Val BAR: 0.8410, Val AUC:0.9070\n","Epoch: 7, Train Loss: 0.1842, Val Loss: 0.3138, Val BAR: 0.8342, Val AUC:0.8961\n","Early stopping triggered\n","Fold: 5\n","resample invoked\n","Epoch: 1, Train Loss: 0.5196, Val Loss: 0.4196, Val BAR: 0.7996, Val AUC:0.8814\n","Epoch: 2, Train Loss: 0.3436, Val Loss: 0.3288, Val BAR: 0.8036, Val AUC:0.8983\n","Epoch: 3, Train Loss: 0.2923, Val Loss: 0.3297, Val BAR: 0.8130, Val AUC:0.9004\n","Epoch: 4, Train Loss: 0.2593, Val Loss: 0.3575, Val BAR: 0.8169, Val AUC:0.8918\n","Epoch: 5, Train Loss: 0.2307, Val Loss: 0.3323, Val BAR: 0.8013, Val AUC:0.8820\n","Epoch: 6, Train Loss: 0.2031, Val Loss: 0.3421, Val BAR: 0.7870, Val AUC:0.8644\n","Epoch: 7, Train Loss: 0.1778, Val Loss: 0.3853, Val BAR: 0.7882, Val AUC:0.8567\n","Early stopping triggered\n","Fold: 6\n","resample invoked\n","Epoch: 1, Train Loss: 0.5044, Val Loss: 0.3717, Val BAR: 0.8166, Val AUC:0.8900\n","Epoch: 2, Train Loss: 0.3399, Val Loss: 0.3462, Val BAR: 0.8195, Val AUC:0.9041\n","Epoch: 3, Train Loss: 0.2960, Val Loss: 0.2888, Val BAR: 0.8263, Val AUC:0.9208\n","Epoch: 4, Train Loss: 0.2640, Val Loss: 0.3454, Val BAR: 0.8327, Val AUC:0.9117\n","Epoch: 5, Train Loss: 0.2367, Val Loss: 0.3241, Val BAR: 0.8332, Val AUC:0.9130\n","Epoch: 6, Train Loss: 0.2128, Val Loss: 0.2909, Val BAR: 0.8205, Val AUC:0.9044\n","Epoch: 7, Train Loss: 0.1887, Val Loss: 0.3302, Val BAR: 0.8285, Val AUC:0.9028\n","Epoch: 8, Train Loss: 0.1694, Val Loss: 0.3292, Val BAR: 0.8256, Val AUC:0.8974\n","Early stopping triggered\n","Fold: 7\n","resample invoked\n","Epoch: 1, Train Loss: 0.5141, Val Loss: 0.4682, Val BAR: 0.7682, Val AUC:0.8646\n","Epoch: 2, Train Loss: 0.3404, Val Loss: 0.3836, Val BAR: 0.8047, Val AUC:0.8881\n","Epoch: 3, Train Loss: 0.2885, Val Loss: 0.3527, Val BAR: 0.7982, Val AUC:0.8741\n","Epoch: 4, Train Loss: 0.2523, Val Loss: 0.3478, Val BAR: 0.7884, Val AUC:0.8713\n","Epoch: 5, Train Loss: 0.2260, Val Loss: 0.3558, Val BAR: 0.7896, Val AUC:0.8682\n","Epoch: 6, Train Loss: 0.2017, Val Loss: 0.3477, Val BAR: 0.7883, Val AUC:0.8520\n","Epoch: 7, Train Loss: 0.1798, Val Loss: 0.3861, Val BAR: 0.7809, Val AUC:0.8528\n","Epoch: 8, Train Loss: 0.1584, Val Loss: 0.3664, Val BAR: 0.7897, Val AUC:0.8366\n","Epoch: 9, Train Loss: 0.1395, Val Loss: 0.4046, Val BAR: 0.7929, Val AUC:0.8499\n","Epoch: 10, Train Loss: 0.1239, Val Loss: 0.4330, Val BAR: 0.7941, Val AUC:0.8429\n","Epoch: 11, Train Loss: 0.1067, Val Loss: 0.4470, Val BAR: 0.7941, Val AUC:0.8421\n","Early stopping triggered\n","Fold: 8\n","resample invoked\n","Epoch: 1, Train Loss: 0.5148, Val Loss: 0.4190, Val BAR: 0.8131, Val AUC:0.8767\n","Epoch: 2, Train Loss: 0.3426, Val Loss: 0.3856, Val BAR: 0.8179, Val AUC:0.8884\n","Epoch: 3, Train Loss: 0.2902, Val Loss: 0.3514, Val BAR: 0.8277, Val AUC:0.8879\n","Epoch: 4, Train Loss: 0.2582, Val Loss: 0.3212, Val BAR: 0.8416, Val AUC:0.8903\n","Epoch: 5, Train Loss: 0.2294, Val Loss: 0.3645, Val BAR: 0.8375, Val AUC:0.8880\n","Epoch: 6, Train Loss: 0.2027, Val Loss: 0.3610, Val BAR: 0.8330, Val AUC:0.8726\n","Epoch: 7, Train Loss: 0.1782, Val Loss: 0.4028, Val BAR: 0.8207, Val AUC:0.8745\n","Epoch: 8, Train Loss: 0.1576, Val Loss: 0.4061, Val BAR: 0.8363, Val AUC:0.8779\n","Epoch: 9, Train Loss: 0.1372, Val Loss: 0.4517, Val BAR: 0.8255, Val AUC:0.8734\n","Early stopping triggered\n","Fold: 9\n","resample invoked\n","Epoch: 1, Train Loss: 0.5119, Val Loss: 0.3515, Val BAR: 0.8248, Val AUC:0.8884\n","Epoch: 2, Train Loss: 0.3461, Val Loss: 0.3178, Val BAR: 0.8432, Val AUC:0.9110\n","Epoch: 3, Train Loss: 0.2944, Val Loss: 0.2809, Val BAR: 0.8456, Val AUC:0.9118\n","Epoch: 4, Train Loss: 0.2600, Val Loss: 0.2807, Val BAR: 0.8352, Val AUC:0.9148\n","Epoch: 5, Train Loss: 0.2312, Val Loss: 0.2981, Val BAR: 0.8354, Val AUC:0.9206\n","Epoch: 6, Train Loss: 0.2055, Val Loss: 0.2958, Val BAR: 0.8392, Val AUC:0.9071\n","Epoch: 7, Train Loss: 0.1814, Val Loss: 0.2946, Val BAR: 0.8427, Val AUC:0.9063\n","Epoch: 8, Train Loss: 0.1607, Val Loss: 0.2814, Val BAR: 0.8421, Val AUC:0.8984\n","Epoch: 9, Train Loss: 0.1379, Val Loss: 0.3153, Val BAR: 0.8368, Val AUC:0.8978\n","Early stopping triggered\n","Fold: 10\n","resample invoked\n","Epoch: 1, Train Loss: 0.5156, Val Loss: 0.3870, Val BAR: 0.8041, Val AUC:0.8827\n","Epoch: 2, Train Loss: 0.3460, Val Loss: 0.3328, Val BAR: 0.8372, Val AUC:0.8995\n","Epoch: 3, Train Loss: 0.2938, Val Loss: 0.3140, Val BAR: 0.8271, Val AUC:0.8955\n","Epoch: 4, Train Loss: 0.2604, Val Loss: 0.2928, Val BAR: 0.8352, Val AUC:0.9006\n","Epoch: 5, Train Loss: 0.2324, Val Loss: 0.3312, Val BAR: 0.8318, Val AUC:0.8911\n","Epoch: 6, Train Loss: 0.2104, Val Loss: 0.3061, Val BAR: 0.8390, Val AUC:0.8921\n","Epoch: 7, Train Loss: 0.1864, Val Loss: 0.3338, Val BAR: 0.8359, Val AUC:0.8872\n","Epoch: 8, Train Loss: 0.1699, Val Loss: 0.3203, Val BAR: 0.8250, Val AUC:0.8843\n","Epoch: 9, Train Loss: 0.1475, Val Loss: 0.3791, Val BAR: 0.8258, Val AUC:0.8807\n","Early stopping triggered\n"]}],"source":["# The best hyperparameter set.\n","bar, auc, y_pred_10_model = cross_validation(\n","    all_x=all_x,\n","    all_y=all_y,\n","    all_test=X_test,\n","    max_hour=max_hour,\n","    max_hour_test=max_hour_test,\n","    num_folds=10,\n","    num_epochs=100,\n","    hidden_dim=256,\n","    layer_dim=2,\n","    batch_size=32,\n","    learning_rate=0.0001,\n","    device=DEVICE,\n","    dropout=0.25,\n","    seq_len=12,\n","    random_seed=20230503\n",")"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":251,"status":"ok","timestamp":1680669987155,"user":{"displayName":"杨宇鹏","userId":"06536559689418416898"},"user_tz":240},"id":"LungHBrYnR9H","outputId":"f6557139-1864-429f-d572-c5d6ed6f486d"},"outputs":[{"name":"stdout","output_type":"stream","text":["CV BAR: [0.8154223729114036, 0.8102538897344833, 0.8131865400864854, 0.8460613845757361, 0.8035672659877333, 0.8262662926909751, 0.7883429187634795, 0.8415983789079897, 0.8351574319213313, 0.8351898598206133] CV AUC: [0.8937678204730459, 0.8973765432098764, 0.9032897119283122, 0.9162868049739062, 0.8982708217895561, 0.92084181194889, 0.8520129403306973, 0.8902979424601408, 0.9148307488653555, 0.9006069069230356]\n"]}],"source":["# 10 Fold Validation Error\n","print(\"CV BAR:\", bar, \"CV AUC:\", auc)"]},{"cell_type":"code","execution_count":47,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1680661321288,"user":{"displayName":"杨宇鹏","userId":"06536559689418416898"},"user_tz":240},"id":"KySoILo_BZno"},"outputs":[],"source":["score = y_pred_10_model.apply(lambda x: round(np.mean(x), 4), axis=1)\n","label = (score > 0.5).astype(\"int\")\n","final_prediction = result_df.copy()\n","final_prediction[\"Outcome\"] = label\n","final_prediction[\"Score\"] = score\n","final_prediction.to_csv(\"test_withlabel.csv\", index=False)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"python39","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
